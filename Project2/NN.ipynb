{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.datasets import fetch_california_housing, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mlrose\n",
    "import time\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load in the data\n",
    "digits = load_digits()\n",
    "\n",
    "#show ample digits\n",
    "#taken from: https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. 12. 13.  5.  0.  0.]\n",
      " [ 0.  0.  0. 11. 16.  9.  0.  0.]\n",
      " [ 0.  0.  3. 15. 16.  6.  0.  0.]\n",
      " [ 0.  7. 15. 16. 16.  2.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  3.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
      " [ 0.  0.  1. 16. 16.  6.  0.  0.]\n",
      " [ 0.  0.  0. 11. 16. 10.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#no need to scale this data\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 2)\n",
    "print(X[1].reshape(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im done\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', random_state = 2, verbose = 2)\n",
    "\n",
    "layer_list = []\n",
    "for i in range(4,10):\n",
    "    layer_list.append((i,))\n",
    "    for j in range(4,10):\n",
    "        layer_list.append((i,j))\n",
    "        for k in range(4,10):\n",
    "            layer_list.append((i,j,k))\n",
    "\n",
    "gs = GridSearchCV(clf, cv=5, iid=False, param_grid={\n",
    "    'hidden_layer_sizes': layer_list\n",
    "    })\n",
    "\n",
    "gs.fit(X, y)\n",
    "print('im done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.21119576, 0.29010081, 0.02317705, 0.33150716, 0.28072414,\n",
      "       0.32285504, 0.33776269, 0.30833726, 0.24062243, 0.22056932,\n",
      "       0.2677989 , 0.28046689, 0.23071947, 0.27687397, 0.28629193,\n",
      "       0.10468512, 0.27004642, 0.28092484, 0.27832799, 0.03236971,\n",
      "       0.28338065, 0.2791862 , 0.23673382, 0.27310686, 0.03655214,\n",
      "       0.28029947, 0.17676506, 0.08027544, 0.29358149, 0.05904384,\n",
      "       0.01215591, 0.2331872 , 0.16044645, 0.24380836, 0.28646951,\n",
      "       0.28119507, 0.20929632, 0.01224713, 0.2131319 , 0.3012527 ,\n",
      "       0.24274459, 0.26717272, 0.29866042, 0.16474724, 0.23775177,\n",
      "       0.16959481, 0.27640991, 0.16274662, 0.20313087, 0.13816156,\n",
      "       0.28626738, 0.01074791, 0.17628145, 0.01104617, 0.17449665,\n",
      "       0.01588225, 0.12831721, 0.01622596, 0.19195743, 0.14015117,\n",
      "       0.06492357, 0.17175565, 0.30377307, 0.29358025, 0.25600171,\n",
      "       0.19914484, 0.2509346 , 0.2813499 , 0.19713602, 0.02578082,\n",
      "       0.29563627, 0.29554944, 0.1019958 , 0.24279466, 0.28483934,\n",
      "       0.29962368, 0.06962619, 0.29461899, 0.13037357, 0.24177699,\n",
      "       0.29251509, 0.15753798, 0.29731765, 0.07372627, 0.29866977,\n",
      "       0.30374804, 0.16154084, 0.23471127, 0.27405829, 0.27992783,\n",
      "       0.32742367, 0.32265573, 0.32395735, 0.33463945, 0.25130043,\n",
      "       0.26066351, 0.28627777, 0.29010129, 0.28983994, 0.29054871,\n",
      "       0.3017128 , 0.2580822 , 0.30474286, 0.3002501 , 0.29460139,\n",
      "       0.2986578 , 0.30085597, 0.32050481, 0.26005173, 0.28977132,\n",
      "       0.30458083, 0.30376596, 0.30347281, 0.26412363, 0.30664082,\n",
      "       0.26110268, 0.29147396, 0.31183453, 0.30326796, 0.30835714,\n",
      "       0.30062361, 0.32198853, 0.25571995, 0.27834392, 0.30678954,\n",
      "       0.31284618, 0.30883784, 0.31793804, 0.30674438, 0.17438426,\n",
      "       0.26423469, 0.38607788, 0.39133043, 0.39012308, 0.43070221,\n",
      "       0.29760585, 0.39011269, 0.20358248, 0.28666129, 0.29314671,\n",
      "       0.30971718, 0.33633761, 0.31992817, 0.34847598, 0.28446236,\n",
      "       0.27529559, 0.29152951, 0.30276589, 0.30767074, 0.29504457,\n",
      "       0.30278277, 0.26433358, 0.26898613, 0.31130333, 0.29807582,\n",
      "       0.31409302, 0.30986295, 0.32094603, 0.26146927, 0.21348033,\n",
      "       0.31846666, 0.32159863, 0.21038213, 0.31514401, 0.323036  ,\n",
      "       0.27959991, 0.25094934, 0.31254754, 0.30981112, 0.31521235,\n",
      "       0.31888556, 0.32103443, 0.21943703, 0.2621304 , 0.0162703 ,\n",
      "       0.29453578, 0.28446898, 0.24286294, 0.28874364, 0.29391723,\n",
      "       0.25691047, 0.30358706, 0.28843112, 0.33393607, 0.25736847,\n",
      "       0.30469146, 0.31732235, 0.14632564, 0.27122641, 0.3190093 ,\n",
      "       0.32511325, 0.27931576, 0.30670981, 0.30934873, 0.26818037,\n",
      "       0.01517687, 0.342377  , 0.32330956, 0.36136122, 0.36074309,\n",
      "       0.32510052, 0.26613688, 0.31690531, 0.38710623, 0.37378488,\n",
      "       0.3474648 , 0.32677145, 0.33640633, 0.27966866, 0.32806854,\n",
      "       0.25955019, 0.33216524, 0.33771434, 0.31815939, 0.33228455,\n",
      "       0.21011086, 0.19916253, 0.24993405, 0.07974319, 0.23208547,\n",
      "       0.32091932, 0.32914133, 0.37276917, 0.30269995, 0.30891018,\n",
      "       0.30375586, 0.33731542, 0.31589727, 0.304772  , 0.34128547,\n",
      "       0.26273961, 0.25114784, 0.32337708, 0.31463919, 0.31462188,\n",
      "       0.30822358, 0.32260561, 0.31160436, 0.33779035, 0.31640792,\n",
      "       0.32708654, 0.35781608, 0.36537104, 0.33645778, 0.30208406,\n",
      "       0.3440176 , 0.34714017, 0.35469098, 0.36093621, 0.36052017,\n",
      "       0.35357804, 0.29858665, 0.25804543, 0.31490493, 0.33522911,\n",
      "       0.29057255, 0.35756388, 0.35247445]), 'std_fit_time': array([0.09866721, 0.01782421, 0.00700662, 0.01106919, 0.09042602,\n",
      "       0.02879891, 0.02536549, 0.0094755 , 0.00601849, 0.1027313 ,\n",
      "       0.0270926 , 0.0071759 , 0.09061991, 0.00427747, 0.00978986,\n",
      "       0.10097365, 0.01106062, 0.00549431, 0.00740475, 0.0449766 ,\n",
      "       0.0086459 , 0.00634508, 0.00583783, 0.00656111, 0.03956128,\n",
      "       0.03512795, 0.07304194, 0.10547489, 0.00824732, 0.09750021,\n",
      "       0.00350261, 0.08345109, 0.1058698 , 0.07621185, 0.00584702,\n",
      "       0.00460605, 0.05518943, 0.0030055 , 0.07849107, 0.0055049 ,\n",
      "       0.10151868, 0.05084523, 0.00383616, 0.05699585, 0.00660815,\n",
      "       0.12389269, 0.01518375, 0.1246878 , 0.10310005, 0.11269496,\n",
      "       0.00278793, 0.00088036, 0.11314287, 0.00127478, 0.13044324,\n",
      "       0.00250805, 0.14010399, 0.00367479, 0.08218953, 0.11828667,\n",
      "       0.10467269, 0.12973801, 0.00558154, 0.00877352, 0.07280683,\n",
      "       0.09000128, 0.07112393, 0.01171244, 0.08420022, 0.02259097,\n",
      "       0.00385857, 0.00388795, 0.11276583, 0.07638961, 0.00469182,\n",
      "       0.00420576, 0.1134265 , 0.00478253, 0.1423078 , 0.00409168,\n",
      "       0.01701777, 0.12473745, 0.01232007, 0.11388179, 0.01317688,\n",
      "       0.00628027, 0.07585574, 0.00493984, 0.00707674, 0.01321278,\n",
      "       0.03452075, 0.01249907, 0.01688398, 0.02710158, 0.01284009,\n",
      "       0.05120047, 0.01013845, 0.00640164, 0.00592085, 0.00374272,\n",
      "       0.00496146, 0.00589932, 0.00646659, 0.0121854 , 0.0068946 ,\n",
      "       0.00366136, 0.00411123, 0.00589116, 0.00881417, 0.01501841,\n",
      "       0.00677689, 0.01167865, 0.0105315 , 0.09225301, 0.00255849,\n",
      "       0.01055453, 0.00539004, 0.01079067, 0.00670067, 0.00323853,\n",
      "       0.00870986, 0.00537707, 0.00398031, 0.00194724, 0.00993879,\n",
      "       0.01237197, 0.01174137, 0.00227668, 0.00197858, 0.06318877,\n",
      "       0.01375487, 0.02745491, 0.04417294, 0.03021076, 0.03194068,\n",
      "       0.17847327, 0.01736665, 0.08288153, 0.00320386, 0.01214918,\n",
      "       0.01784164, 0.02280097, 0.0167716 , 0.02225651, 0.02581471,\n",
      "       0.06186348, 0.04037985, 0.00409933, 0.01357826, 0.00508876,\n",
      "       0.00291681, 0.00558811, 0.05970796, 0.01392136, 0.00860523,\n",
      "       0.01625341, 0.00397049, 0.00370544, 0.00719269, 0.10659839,\n",
      "       0.0181978 , 0.0079824 , 0.1188662 , 0.01050466, 0.00649358,\n",
      "       0.00777864, 0.11575543, 0.01023158, 0.01119348, 0.00415765,\n",
      "       0.00359935, 0.00355149, 0.00703139, 0.0076523 , 0.00494157,\n",
      "       0.00293591, 0.00708118, 0.09360305, 0.00427702, 0.00855202,\n",
      "       0.00435579, 0.00989295, 0.00655622, 0.00977655, 0.09311816,\n",
      "       0.01308868, 0.00778384, 0.09563193, 0.04194254, 0.01373393,\n",
      "       0.01070138, 0.07714243, 0.00403598, 0.00705605, 0.00891189,\n",
      "       0.00446155, 0.01737403, 0.01637241, 0.020899  , 0.02093984,\n",
      "       0.01062533, 0.03092811, 0.02435065, 0.03333009, 0.02103157,\n",
      "       0.00883013, 0.00239988, 0.00606616, 0.01133115, 0.00705809,\n",
      "       0.14858712, 0.01807078, 0.01588479, 0.03009642, 0.0111753 ,\n",
      "       0.00251536, 0.09292607, 0.11450739, 0.12401591, 0.10352261,\n",
      "       0.02229706, 0.01255406, 0.00908207, 0.01762406, 0.00964036,\n",
      "       0.01287834, 0.01484908, 0.00679266, 0.00833914, 0.01221724,\n",
      "       0.00441214, 0.05740712, 0.01152258, 0.00482624, 0.00432904,\n",
      "       0.003872  , 0.00769752, 0.04293583, 0.01802612, 0.01976635,\n",
      "       0.05692201, 0.01006442, 0.00614001, 0.0607002 , 0.01021989,\n",
      "       0.00778776, 0.00809307, 0.01106903, 0.00876945, 0.02116139,\n",
      "       0.01093285, 0.00984696, 0.11567842, 0.00556034, 0.00864893,\n",
      "       0.13266035, 0.00675668, 0.00671915]), 'mean_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.00625024, 0.00312505, 0.        , 0.00312524, 0.00312481,\n",
      "       0.00160575, 0.00200348, 0.        , 0.00200496, 0.00040274,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.00110302, 0.        , 0.0011045 , 0.        ,\n",
      "       0.00165076, 0.        , 0.        , 0.        , 0.00406022,\n",
      "       0.        , 0.00050197, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00020237, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00100064, 0.00090051, 0.        ,\n",
      "       0.        , 0.        , 0.00040226, 0.        , 0.        ,\n",
      "       0.00100336, 0.00130301, 0.00050211, 0.        , 0.00140395,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00110369,\n",
      "       0.        , 0.        , 0.        , 0.00100207, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00060282,\n",
      "       0.        , 0.00030169, 0.00160604, 0.00010695, 0.00240707,\n",
      "       0.        , 0.00030208, 0.00040317, 0.00060153, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00203485,\n",
      "       0.        , 0.        , 0.00100083, 0.00020785, 0.00310936,\n",
      "       0.        , 0.        , 0.        , 0.00312481, 0.        ,\n",
      "       0.00040236, 0.003125  , 0.        , 0.00198755, 0.        ,\n",
      "       0.00100107, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.00040164, 0.        , 0.        , 0.00200148,\n",
      "       0.        , 0.        , 0.00290971, 0.        , 0.00110531,\n",
      "       0.        , 0.        , 0.00110221, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00140457, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00070205, 0.00120215, 0.        ,\n",
      "       0.        , 0.00407863, 0.00170293, 0.        , 0.00205598,\n",
      "       0.        , 0.        , 0.        , 0.00240417, 0.        ,\n",
      "       0.        , 0.00100079, 0.00100079, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00040245, 0.00160742, 0.0030673 ,\n",
      "       0.00040164, 0.00030246, 0.00040188, 0.        , 0.        ,\n",
      "       0.00040221, 0.        , 0.        , 0.0011023 , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.00163441, 0.0014019 ,\n",
      "       0.00040212, 0.0016335 , 0.00040269, 0.        , 0.00040784,\n",
      "       0.00010176, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00199895, 0.        , 0.        ,\n",
      "       0.00040278, 0.00100212, 0.00140672, 0.        , 0.        ,\n",
      "       0.00211592, 0.00362821, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.00110383, 0.        , 0.00050211, 0.        ,\n",
      "       0.00190449, 0.00100613, 0.        , 0.        , 0.        ,\n",
      "       0.00100055, 0.00100689, 0.        , 0.00100408, 0.        ,\n",
      "       0.        , 0.        , 0.00130219, 0.        , 0.        ,\n",
      "       0.        , 0.00209274, 0.        , 0.00040226, 0.00100098,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00070806,\n",
      "       0.00040221, 0.00207615, 0.00100069, 0.        , 0.00164375,\n",
      "       0.00100412, 0.        , 0.00307913, 0.        , 0.        ,\n",
      "       0.00040154, 0.        , 0.        , 0.00060453, 0.00040193,\n",
      "       0.00020218, 0.00208983, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.003125  ,\n",
      "       0.        , 0.        , 0.        , 0.00312467, 0.        ,\n",
      "       0.00305281, 0.00100298, 0.00199251, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        ]), 'std_score_time': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.00765495, 0.0062501 , 0.        , 0.00625048, 0.00624962,\n",
      "       0.0032115 , 0.00400696, 0.        , 0.00310315, 0.00080547,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.00220604, 0.        , 0.00143342, 0.        ,\n",
      "       0.00330153, 0.        , 0.        , 0.        , 0.00497452,\n",
      "       0.        , 0.00100393, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00040474, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00200129, 0.00180101, 0.        ,\n",
      "       0.        , 0.        , 0.00080452, 0.        , 0.        ,\n",
      "       0.00200672, 0.00260601, 0.00100422, 0.        , 0.0028079 ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00220737,\n",
      "       0.        , 0.        , 0.        , 0.00200415, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00120564,\n",
      "       0.        , 0.00060339, 0.00166051, 0.00021391, 0.00294296,\n",
      "       0.        , 0.00060415, 0.00080633, 0.00120306, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00406971,\n",
      "       0.        , 0.        , 0.00200167, 0.00041571, 0.00383837,\n",
      "       0.        , 0.        , 0.        , 0.00624962, 0.        ,\n",
      "       0.00080471, 0.00625   , 0.        , 0.00397511, 0.        ,\n",
      "       0.00200214, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.00080328, 0.        , 0.        , 0.0024513 ,\n",
      "       0.        , 0.        , 0.00411788, 0.        , 0.00221062,\n",
      "       0.        , 0.        , 0.00220442, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00196351, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00140409, 0.00194067, 0.        ,\n",
      "       0.        , 0.00499887, 0.00340586, 0.        , 0.00411196,\n",
      "       0.        , 0.        , 0.        , 0.00301273, 0.        ,\n",
      "       0.        , 0.00200157, 0.00200157, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.0008049 , 0.00206892, 0.0037568 ,\n",
      "       0.00080328, 0.00060492, 0.00080376, 0.        , 0.        ,\n",
      "       0.00080442, 0.        , 0.        , 0.00220461, 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.00326881, 0.0028038 ,\n",
      "       0.00080423, 0.003267  , 0.00080538, 0.        , 0.00081568,\n",
      "       0.00020351, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.0039979 , 0.        , 0.        ,\n",
      "       0.00080557, 0.00200424, 0.00196789, 0.        , 0.        ,\n",
      "       0.00423183, 0.00449384, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.00220766, 0.        , 0.00100422, 0.        ,\n",
      "       0.00380898, 0.00201225, 0.        , 0.        , 0.        ,\n",
      "       0.00200109, 0.00201378, 0.        , 0.00200815, 0.        ,\n",
      "       0.        , 0.        , 0.00260439, 0.        , 0.        ,\n",
      "       0.        , 0.00418549, 0.        , 0.00080452, 0.00200195,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00141611,\n",
      "       0.00080442, 0.0041523 , 0.00200138, 0.        , 0.00328751,\n",
      "       0.00200825, 0.        , 0.0041381 , 0.        , 0.        ,\n",
      "       0.00080309, 0.        , 0.        , 0.0007404 , 0.00080385,\n",
      "       0.00040436, 0.00417967, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.00625   ,\n",
      "       0.        , 0.        , 0.        , 0.00624933, 0.        ,\n",
      "       0.00409172, 0.00200596, 0.00398502, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        ]), 'param_hidden_layer_sizes': masked_array(data=[(4,), (4, 4), (4, 4, 4), (4, 4, 5), (4, 4, 6),\n",
      "                   (4, 4, 7), (4, 4, 8), (4, 4, 9), (4, 5), (4, 5, 4),\n",
      "                   (4, 5, 5), (4, 5, 6), (4, 5, 7), (4, 5, 8), (4, 5, 9),\n",
      "                   (4, 6), (4, 6, 4), (4, 6, 5), (4, 6, 6), (4, 6, 7),\n",
      "                   (4, 6, 8), (4, 6, 9), (4, 7), (4, 7, 4), (4, 7, 5),\n",
      "                   (4, 7, 6), (4, 7, 7), (4, 7, 8), (4, 7, 9), (4, 8),\n",
      "                   (4, 8, 4), (4, 8, 5), (4, 8, 6), (4, 8, 7), (4, 8, 8),\n",
      "                   (4, 8, 9), (4, 9), (4, 9, 4), (4, 9, 5), (4, 9, 6),\n",
      "                   (4, 9, 7), (4, 9, 8), (4, 9, 9), (5,), (5, 4),\n",
      "                   (5, 4, 4), (5, 4, 5), (5, 4, 6), (5, 4, 7), (5, 4, 8),\n",
      "                   (5, 4, 9), (5, 5), (5, 5, 4), (5, 5, 5), (5, 5, 6),\n",
      "                   (5, 5, 7), (5, 5, 8), (5, 5, 9), (5, 6), (5, 6, 4),\n",
      "                   (5, 6, 5), (5, 6, 6), (5, 6, 7), (5, 6, 8), (5, 6, 9),\n",
      "                   (5, 7), (5, 7, 4), (5, 7, 5), (5, 7, 6), (5, 7, 7),\n",
      "                   (5, 7, 8), (5, 7, 9), (5, 8), (5, 8, 4), (5, 8, 5),\n",
      "                   (5, 8, 6), (5, 8, 7), (5, 8, 8), (5, 8, 9), (5, 9),\n",
      "                   (5, 9, 4), (5, 9, 5), (5, 9, 6), (5, 9, 7), (5, 9, 8),\n",
      "                   (5, 9, 9), (6,), (6, 4), (6, 4, 4), (6, 4, 5),\n",
      "                   (6, 4, 6), (6, 4, 7), (6, 4, 8), (6, 4, 9), (6, 5),\n",
      "                   (6, 5, 4), (6, 5, 5), (6, 5, 6), (6, 5, 7), (6, 5, 8),\n",
      "                   (6, 5, 9), (6, 6), (6, 6, 4), (6, 6, 5), (6, 6, 6),\n",
      "                   (6, 6, 7), (6, 6, 8), (6, 6, 9), (6, 7), (6, 7, 4),\n",
      "                   (6, 7, 5), (6, 7, 6), (6, 7, 7), (6, 7, 8), (6, 7, 9),\n",
      "                   (6, 8), (6, 8, 4), (6, 8, 5), (6, 8, 6), (6, 8, 7),\n",
      "                   (6, 8, 8), (6, 8, 9), (6, 9), (6, 9, 4), (6, 9, 5),\n",
      "                   (6, 9, 6), (6, 9, 7), (6, 9, 8), (6, 9, 9), (7,),\n",
      "                   (7, 4), (7, 4, 4), (7, 4, 5), (7, 4, 6), (7, 4, 7),\n",
      "                   (7, 4, 8), (7, 4, 9), (7, 5), (7, 5, 4), (7, 5, 5),\n",
      "                   (7, 5, 6), (7, 5, 7), (7, 5, 8), (7, 5, 9), (7, 6),\n",
      "                   (7, 6, 4), (7, 6, 5), (7, 6, 6), (7, 6, 7), (7, 6, 8),\n",
      "                   (7, 6, 9), (7, 7), (7, 7, 4), (7, 7, 5), (7, 7, 6),\n",
      "                   (7, 7, 7), (7, 7, 8), (7, 7, 9), (7, 8), (7, 8, 4),\n",
      "                   (7, 8, 5), (7, 8, 6), (7, 8, 7), (7, 8, 8), (7, 8, 9),\n",
      "                   (7, 9), (7, 9, 4), (7, 9, 5), (7, 9, 6), (7, 9, 7),\n",
      "                   (7, 9, 8), (7, 9, 9), (8,), (8, 4), (8, 4, 4),\n",
      "                   (8, 4, 5), (8, 4, 6), (8, 4, 7), (8, 4, 8), (8, 4, 9),\n",
      "                   (8, 5), (8, 5, 4), (8, 5, 5), (8, 5, 6), (8, 5, 7),\n",
      "                   (8, 5, 8), (8, 5, 9), (8, 6), (8, 6, 4), (8, 6, 5),\n",
      "                   (8, 6, 6), (8, 6, 7), (8, 6, 8), (8, 6, 9), (8, 7),\n",
      "                   (8, 7, 4), (8, 7, 5), (8, 7, 6), (8, 7, 7), (8, 7, 8),\n",
      "                   (8, 7, 9), (8, 8), (8, 8, 4), (8, 8, 5), (8, 8, 6),\n",
      "                   (8, 8, 7), (8, 8, 8), (8, 8, 9), (8, 9), (8, 9, 4),\n",
      "                   (8, 9, 5), (8, 9, 6), (8, 9, 7), (8, 9, 8), (8, 9, 9),\n",
      "                   (9,), (9, 4), (9, 4, 4), (9, 4, 5), (9, 4, 6),\n",
      "                   (9, 4, 7), (9, 4, 8), (9, 4, 9), (9, 5), (9, 5, 4),\n",
      "                   (9, 5, 5), (9, 5, 6), (9, 5, 7), (9, 5, 8), (9, 5, 9),\n",
      "                   (9, 6), (9, 6, 4), (9, 6, 5), (9, 6, 6), (9, 6, 7),\n",
      "                   (9, 6, 8), (9, 6, 9), (9, 7), (9, 7, 4), (9, 7, 5),\n",
      "                   (9, 7, 6), (9, 7, 7), (9, 7, 8), (9, 7, 9), (9, 8),\n",
      "                   (9, 8, 4), (9, 8, 5), (9, 8, 6), (9, 8, 7), (9, 8, 8),\n",
      "                   (9, 8, 9), (9, 9), (9, 9, 4), (9, 9, 5), (9, 9, 6),\n",
      "                   (9, 9, 7), (9, 9, 8), (9, 9, 9)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'hidden_layer_sizes': (4,)}, {'hidden_layer_sizes': (4, 4)}, {'hidden_layer_sizes': (4, 4, 4)}, {'hidden_layer_sizes': (4, 4, 5)}, {'hidden_layer_sizes': (4, 4, 6)}, {'hidden_layer_sizes': (4, 4, 7)}, {'hidden_layer_sizes': (4, 4, 8)}, {'hidden_layer_sizes': (4, 4, 9)}, {'hidden_layer_sizes': (4, 5)}, {'hidden_layer_sizes': (4, 5, 4)}, {'hidden_layer_sizes': (4, 5, 5)}, {'hidden_layer_sizes': (4, 5, 6)}, {'hidden_layer_sizes': (4, 5, 7)}, {'hidden_layer_sizes': (4, 5, 8)}, {'hidden_layer_sizes': (4, 5, 9)}, {'hidden_layer_sizes': (4, 6)}, {'hidden_layer_sizes': (4, 6, 4)}, {'hidden_layer_sizes': (4, 6, 5)}, {'hidden_layer_sizes': (4, 6, 6)}, {'hidden_layer_sizes': (4, 6, 7)}, {'hidden_layer_sizes': (4, 6, 8)}, {'hidden_layer_sizes': (4, 6, 9)}, {'hidden_layer_sizes': (4, 7)}, {'hidden_layer_sizes': (4, 7, 4)}, {'hidden_layer_sizes': (4, 7, 5)}, {'hidden_layer_sizes': (4, 7, 6)}, {'hidden_layer_sizes': (4, 7, 7)}, {'hidden_layer_sizes': (4, 7, 8)}, {'hidden_layer_sizes': (4, 7, 9)}, {'hidden_layer_sizes': (4, 8)}, {'hidden_layer_sizes': (4, 8, 4)}, {'hidden_layer_sizes': (4, 8, 5)}, {'hidden_layer_sizes': (4, 8, 6)}, {'hidden_layer_sizes': (4, 8, 7)}, {'hidden_layer_sizes': (4, 8, 8)}, {'hidden_layer_sizes': (4, 8, 9)}, {'hidden_layer_sizes': (4, 9)}, {'hidden_layer_sizes': (4, 9, 4)}, {'hidden_layer_sizes': (4, 9, 5)}, {'hidden_layer_sizes': (4, 9, 6)}, {'hidden_layer_sizes': (4, 9, 7)}, {'hidden_layer_sizes': (4, 9, 8)}, {'hidden_layer_sizes': (4, 9, 9)}, {'hidden_layer_sizes': (5,)}, {'hidden_layer_sizes': (5, 4)}, {'hidden_layer_sizes': (5, 4, 4)}, {'hidden_layer_sizes': (5, 4, 5)}, {'hidden_layer_sizes': (5, 4, 6)}, {'hidden_layer_sizes': (5, 4, 7)}, {'hidden_layer_sizes': (5, 4, 8)}, {'hidden_layer_sizes': (5, 4, 9)}, {'hidden_layer_sizes': (5, 5)}, {'hidden_layer_sizes': (5, 5, 4)}, {'hidden_layer_sizes': (5, 5, 5)}, {'hidden_layer_sizes': (5, 5, 6)}, {'hidden_layer_sizes': (5, 5, 7)}, {'hidden_layer_sizes': (5, 5, 8)}, {'hidden_layer_sizes': (5, 5, 9)}, {'hidden_layer_sizes': (5, 6)}, {'hidden_layer_sizes': (5, 6, 4)}, {'hidden_layer_sizes': (5, 6, 5)}, {'hidden_layer_sizes': (5, 6, 6)}, {'hidden_layer_sizes': (5, 6, 7)}, {'hidden_layer_sizes': (5, 6, 8)}, {'hidden_layer_sizes': (5, 6, 9)}, {'hidden_layer_sizes': (5, 7)}, {'hidden_layer_sizes': (5, 7, 4)}, {'hidden_layer_sizes': (5, 7, 5)}, {'hidden_layer_sizes': (5, 7, 6)}, {'hidden_layer_sizes': (5, 7, 7)}, {'hidden_layer_sizes': (5, 7, 8)}, {'hidden_layer_sizes': (5, 7, 9)}, {'hidden_layer_sizes': (5, 8)}, {'hidden_layer_sizes': (5, 8, 4)}, {'hidden_layer_sizes': (5, 8, 5)}, {'hidden_layer_sizes': (5, 8, 6)}, {'hidden_layer_sizes': (5, 8, 7)}, {'hidden_layer_sizes': (5, 8, 8)}, {'hidden_layer_sizes': (5, 8, 9)}, {'hidden_layer_sizes': (5, 9)}, {'hidden_layer_sizes': (5, 9, 4)}, {'hidden_layer_sizes': (5, 9, 5)}, {'hidden_layer_sizes': (5, 9, 6)}, {'hidden_layer_sizes': (5, 9, 7)}, {'hidden_layer_sizes': (5, 9, 8)}, {'hidden_layer_sizes': (5, 9, 9)}, {'hidden_layer_sizes': (6,)}, {'hidden_layer_sizes': (6, 4)}, {'hidden_layer_sizes': (6, 4, 4)}, {'hidden_layer_sizes': (6, 4, 5)}, {'hidden_layer_sizes': (6, 4, 6)}, {'hidden_layer_sizes': (6, 4, 7)}, {'hidden_layer_sizes': (6, 4, 8)}, {'hidden_layer_sizes': (6, 4, 9)}, {'hidden_layer_sizes': (6, 5)}, {'hidden_layer_sizes': (6, 5, 4)}, {'hidden_layer_sizes': (6, 5, 5)}, {'hidden_layer_sizes': (6, 5, 6)}, {'hidden_layer_sizes': (6, 5, 7)}, {'hidden_layer_sizes': (6, 5, 8)}, {'hidden_layer_sizes': (6, 5, 9)}, {'hidden_layer_sizes': (6, 6)}, {'hidden_layer_sizes': (6, 6, 4)}, {'hidden_layer_sizes': (6, 6, 5)}, {'hidden_layer_sizes': (6, 6, 6)}, {'hidden_layer_sizes': (6, 6, 7)}, {'hidden_layer_sizes': (6, 6, 8)}, {'hidden_layer_sizes': (6, 6, 9)}, {'hidden_layer_sizes': (6, 7)}, {'hidden_layer_sizes': (6, 7, 4)}, {'hidden_layer_sizes': (6, 7, 5)}, {'hidden_layer_sizes': (6, 7, 6)}, {'hidden_layer_sizes': (6, 7, 7)}, {'hidden_layer_sizes': (6, 7, 8)}, {'hidden_layer_sizes': (6, 7, 9)}, {'hidden_layer_sizes': (6, 8)}, {'hidden_layer_sizes': (6, 8, 4)}, {'hidden_layer_sizes': (6, 8, 5)}, {'hidden_layer_sizes': (6, 8, 6)}, {'hidden_layer_sizes': (6, 8, 7)}, {'hidden_layer_sizes': (6, 8, 8)}, {'hidden_layer_sizes': (6, 8, 9)}, {'hidden_layer_sizes': (6, 9)}, {'hidden_layer_sizes': (6, 9, 4)}, {'hidden_layer_sizes': (6, 9, 5)}, {'hidden_layer_sizes': (6, 9, 6)}, {'hidden_layer_sizes': (6, 9, 7)}, {'hidden_layer_sizes': (6, 9, 8)}, {'hidden_layer_sizes': (6, 9, 9)}, {'hidden_layer_sizes': (7,)}, {'hidden_layer_sizes': (7, 4)}, {'hidden_layer_sizes': (7, 4, 4)}, {'hidden_layer_sizes': (7, 4, 5)}, {'hidden_layer_sizes': (7, 4, 6)}, {'hidden_layer_sizes': (7, 4, 7)}, {'hidden_layer_sizes': (7, 4, 8)}, {'hidden_layer_sizes': (7, 4, 9)}, {'hidden_layer_sizes': (7, 5)}, {'hidden_layer_sizes': (7, 5, 4)}, {'hidden_layer_sizes': (7, 5, 5)}, {'hidden_layer_sizes': (7, 5, 6)}, {'hidden_layer_sizes': (7, 5, 7)}, {'hidden_layer_sizes': (7, 5, 8)}, {'hidden_layer_sizes': (7, 5, 9)}, {'hidden_layer_sizes': (7, 6)}, {'hidden_layer_sizes': (7, 6, 4)}, {'hidden_layer_sizes': (7, 6, 5)}, {'hidden_layer_sizes': (7, 6, 6)}, {'hidden_layer_sizes': (7, 6, 7)}, {'hidden_layer_sizes': (7, 6, 8)}, {'hidden_layer_sizes': (7, 6, 9)}, {'hidden_layer_sizes': (7, 7)}, {'hidden_layer_sizes': (7, 7, 4)}, {'hidden_layer_sizes': (7, 7, 5)}, {'hidden_layer_sizes': (7, 7, 6)}, {'hidden_layer_sizes': (7, 7, 7)}, {'hidden_layer_sizes': (7, 7, 8)}, {'hidden_layer_sizes': (7, 7, 9)}, {'hidden_layer_sizes': (7, 8)}, {'hidden_layer_sizes': (7, 8, 4)}, {'hidden_layer_sizes': (7, 8, 5)}, {'hidden_layer_sizes': (7, 8, 6)}, {'hidden_layer_sizes': (7, 8, 7)}, {'hidden_layer_sizes': (7, 8, 8)}, {'hidden_layer_sizes': (7, 8, 9)}, {'hidden_layer_sizes': (7, 9)}, {'hidden_layer_sizes': (7, 9, 4)}, {'hidden_layer_sizes': (7, 9, 5)}, {'hidden_layer_sizes': (7, 9, 6)}, {'hidden_layer_sizes': (7, 9, 7)}, {'hidden_layer_sizes': (7, 9, 8)}, {'hidden_layer_sizes': (7, 9, 9)}, {'hidden_layer_sizes': (8,)}, {'hidden_layer_sizes': (8, 4)}, {'hidden_layer_sizes': (8, 4, 4)}, {'hidden_layer_sizes': (8, 4, 5)}, {'hidden_layer_sizes': (8, 4, 6)}, {'hidden_layer_sizes': (8, 4, 7)}, {'hidden_layer_sizes': (8, 4, 8)}, {'hidden_layer_sizes': (8, 4, 9)}, {'hidden_layer_sizes': (8, 5)}, {'hidden_layer_sizes': (8, 5, 4)}, {'hidden_layer_sizes': (8, 5, 5)}, {'hidden_layer_sizes': (8, 5, 6)}, {'hidden_layer_sizes': (8, 5, 7)}, {'hidden_layer_sizes': (8, 5, 8)}, {'hidden_layer_sizes': (8, 5, 9)}, {'hidden_layer_sizes': (8, 6)}, {'hidden_layer_sizes': (8, 6, 4)}, {'hidden_layer_sizes': (8, 6, 5)}, {'hidden_layer_sizes': (8, 6, 6)}, {'hidden_layer_sizes': (8, 6, 7)}, {'hidden_layer_sizes': (8, 6, 8)}, {'hidden_layer_sizes': (8, 6, 9)}, {'hidden_layer_sizes': (8, 7)}, {'hidden_layer_sizes': (8, 7, 4)}, {'hidden_layer_sizes': (8, 7, 5)}, {'hidden_layer_sizes': (8, 7, 6)}, {'hidden_layer_sizes': (8, 7, 7)}, {'hidden_layer_sizes': (8, 7, 8)}, {'hidden_layer_sizes': (8, 7, 9)}, {'hidden_layer_sizes': (8, 8)}, {'hidden_layer_sizes': (8, 8, 4)}, {'hidden_layer_sizes': (8, 8, 5)}, {'hidden_layer_sizes': (8, 8, 6)}, {'hidden_layer_sizes': (8, 8, 7)}, {'hidden_layer_sizes': (8, 8, 8)}, {'hidden_layer_sizes': (8, 8, 9)}, {'hidden_layer_sizes': (8, 9)}, {'hidden_layer_sizes': (8, 9, 4)}, {'hidden_layer_sizes': (8, 9, 5)}, {'hidden_layer_sizes': (8, 9, 6)}, {'hidden_layer_sizes': (8, 9, 7)}, {'hidden_layer_sizes': (8, 9, 8)}, {'hidden_layer_sizes': (8, 9, 9)}, {'hidden_layer_sizes': (9,)}, {'hidden_layer_sizes': (9, 4)}, {'hidden_layer_sizes': (9, 4, 4)}, {'hidden_layer_sizes': (9, 4, 5)}, {'hidden_layer_sizes': (9, 4, 6)}, {'hidden_layer_sizes': (9, 4, 7)}, {'hidden_layer_sizes': (9, 4, 8)}, {'hidden_layer_sizes': (9, 4, 9)}, {'hidden_layer_sizes': (9, 5)}, {'hidden_layer_sizes': (9, 5, 4)}, {'hidden_layer_sizes': (9, 5, 5)}, {'hidden_layer_sizes': (9, 5, 6)}, {'hidden_layer_sizes': (9, 5, 7)}, {'hidden_layer_sizes': (9, 5, 8)}, {'hidden_layer_sizes': (9, 5, 9)}, {'hidden_layer_sizes': (9, 6)}, {'hidden_layer_sizes': (9, 6, 4)}, {'hidden_layer_sizes': (9, 6, 5)}, {'hidden_layer_sizes': (9, 6, 6)}, {'hidden_layer_sizes': (9, 6, 7)}, {'hidden_layer_sizes': (9, 6, 8)}, {'hidden_layer_sizes': (9, 6, 9)}, {'hidden_layer_sizes': (9, 7)}, {'hidden_layer_sizes': (9, 7, 4)}, {'hidden_layer_sizes': (9, 7, 5)}, {'hidden_layer_sizes': (9, 7, 6)}, {'hidden_layer_sizes': (9, 7, 7)}, {'hidden_layer_sizes': (9, 7, 8)}, {'hidden_layer_sizes': (9, 7, 9)}, {'hidden_layer_sizes': (9, 8)}, {'hidden_layer_sizes': (9, 8, 4)}, {'hidden_layer_sizes': (9, 8, 5)}, {'hidden_layer_sizes': (9, 8, 6)}, {'hidden_layer_sizes': (9, 8, 7)}, {'hidden_layer_sizes': (9, 8, 8)}, {'hidden_layer_sizes': (9, 8, 9)}, {'hidden_layer_sizes': (9, 9)}, {'hidden_layer_sizes': (9, 9, 4)}, {'hidden_layer_sizes': (9, 9, 5)}, {'hidden_layer_sizes': (9, 9, 6)}, {'hidden_layer_sizes': (9, 9, 7)}, {'hidden_layer_sizes': (9, 9, 8)}, {'hidden_layer_sizes': (9, 9, 9)}], 'split0_test_score': array([0.30769231, 0.42307692, 0.10164835, 0.51098901, 0.66758242,\n",
      "       0.64285714, 0.48351648, 0.73901099, 0.46428571, 0.48626374,\n",
      "       0.61263736, 0.55769231, 0.18681319, 0.43956044, 0.35164835,\n",
      "       0.34615385, 0.53021978, 0.40659341, 0.27472527, 0.10164835,\n",
      "       0.58791209, 0.3956044 , 0.28021978, 0.28571429, 0.10164835,\n",
      "       0.48901099, 0.1978022 , 0.10164835, 0.44230769, 0.24450549,\n",
      "       0.10164835, 0.37087912, 0.18406593, 0.26648352, 0.44230769,\n",
      "       0.48626374, 0.39285714, 0.10164835, 0.20054945, 0.65934066,\n",
      "       0.30769231, 0.28021978, 0.59340659, 0.60164835, 0.49725275,\n",
      "       0.43956044, 0.32967033, 0.3489011 , 0.54395604, 0.11813187,\n",
      "       0.47527473, 0.10164835, 0.29945055, 0.10164835, 0.52472527,\n",
      "       0.10164835, 0.78021978, 0.10164835, 0.31043956, 0.37362637,\n",
      "       0.61263736, 0.34065934, 0.29945055, 0.49175824, 0.3543956 ,\n",
      "       0.37087912, 0.43131868, 0.32142857, 0.46978022, 0.11538462,\n",
      "       0.61538462, 0.67032967, 0.10164835, 0.58516484, 0.59340659,\n",
      "       0.67582418, 0.10164835, 0.56593407, 0.10164835, 0.43681319,\n",
      "       0.24175824, 0.30494505, 0.34340659, 0.10164835, 0.50549451,\n",
      "       0.41483516, 0.24450549, 0.5467033 , 0.42307692, 0.48626374,\n",
      "       0.7032967 , 0.79945055, 0.57692308, 0.67032967, 0.53296703,\n",
      "       0.56593407, 0.65384615, 0.70054945, 0.33791209, 0.35164835,\n",
      "       0.61813187, 0.78021978, 0.68406593, 0.72252747, 0.3489011 ,\n",
      "       0.47802198, 0.48901099, 0.79120879, 0.73076923, 0.49175824,\n",
      "       0.86538462, 0.52747253, 0.35989011, 0.5989011 , 0.6456044 ,\n",
      "       0.60989011, 0.5       , 0.74725275, 0.79395604, 0.77747253,\n",
      "       0.35714286, 0.86263736, 0.35714286, 0.37087912, 0.63461538,\n",
      "       0.63461538, 0.42032967, 0.71978022, 0.65384615, 0.72252747,\n",
      "       0.65659341, 0.52472527, 0.64285714, 0.66758242, 0.38461538,\n",
      "       0.47527473, 0.70054945, 0.21703297, 0.48626374, 0.46978022,\n",
      "       0.48076923, 0.60989011, 0.34340659, 0.73901099, 0.73901099,\n",
      "       0.57142857, 0.47252747, 0.70054945, 0.73076923, 0.41758242,\n",
      "       0.80769231, 0.73351648, 0.39835165, 0.67307692, 0.37087912,\n",
      "       0.57692308, 0.62637363, 0.84065934, 0.66758242, 0.34340659,\n",
      "       0.73076923, 0.7967033 , 0.52472527, 0.68406593, 0.74450549,\n",
      "       0.8956044 , 0.18956044, 0.68956044, 0.42582418, 0.40934066,\n",
      "       0.68681319, 0.70054945, 0.87362637, 0.55769231, 0.10164835,\n",
      "       0.73626374, 0.35714286, 0.32417582, 0.35989011, 0.29945055,\n",
      "       0.64010989, 0.59065934, 0.49450549, 0.79395604, 0.71428571,\n",
      "       0.79120879, 0.73076923, 0.18406593, 0.56318681, 0.62912088,\n",
      "       0.79945055, 0.4532967 , 0.56868132, 0.65659341, 0.40384615,\n",
      "       0.10164835, 0.3543956 , 0.84340659, 0.75      , 0.70879121,\n",
      "       0.71703297, 0.85714286, 0.71978022, 0.38736264, 0.80769231,\n",
      "       0.83241758, 0.87637363, 0.87912088, 0.83791209, 0.75274725,\n",
      "       0.26373626, 0.61813187, 0.86538462, 0.87912088, 0.6043956 ,\n",
      "       0.49175824, 0.3489011 , 0.56043956, 0.10164835, 0.71153846,\n",
      "       0.35714286, 0.8489011 , 0.8489011 , 0.66208791, 0.86538462,\n",
      "       0.52747253, 0.82142857, 0.8543956 , 0.45604396, 0.85989011,\n",
      "       0.64835165, 0.36538462, 0.84065934, 0.89010989, 0.85989011,\n",
      "       0.75824176, 0.79120879, 0.60989011, 0.71153846, 0.5467033 ,\n",
      "       0.72252747, 0.50274725, 0.71978022, 0.78571429, 0.83791209,\n",
      "       0.82142857, 0.78846154, 0.72802198, 0.85989011, 0.64010989,\n",
      "       0.83241758, 0.84065934, 0.70879121, 0.70879121, 0.82967033,\n",
      "       0.6978022 , 0.76373626, 0.77747253]), 'split1_test_score': array([0.32872928, 0.36187845, 0.10220994, 0.61325967, 0.54143646,\n",
      "       0.47513812, 0.45027624, 0.72375691, 0.45027624, 0.35635359,\n",
      "       0.57458564, 0.37292818, 0.2320442 , 0.34254144, 0.28453039,\n",
      "       0.22375691, 0.25966851, 0.32596685, 0.48066298, 0.10220994,\n",
      "       0.40883978, 0.3480663 , 0.22375691, 0.27624309, 0.18508287,\n",
      "       0.50828729, 0.20165746, 0.30110497, 0.32044199, 0.10220994,\n",
      "       0.10220994, 0.24861878, 0.10220994, 0.2679558 , 0.56906077,\n",
      "       0.52486188, 0.3038674 , 0.10220994, 0.20165746, 0.6878453 ,\n",
      "       0.29834254, 0.27071823, 0.53314917, 0.23480663, 0.43646409,\n",
      "       0.10220994, 0.30662983, 0.10220994, 0.50552486, 0.17127072,\n",
      "       0.45856354, 0.10220994, 0.13535912, 0.10220994, 0.10220994,\n",
      "       0.10220994, 0.5718232 , 0.10220994, 0.39226519, 0.09944751,\n",
      "       0.10220994, 0.10220994, 0.49171271, 0.46961326, 0.29834254,\n",
      "       0.55524862, 0.39226519, 0.28453039, 0.38121547, 0.10220994,\n",
      "       0.70718232, 0.61049724, 0.10220994, 0.40607735, 0.58287293,\n",
      "       0.66850829, 0.44198895, 0.32872928, 0.70441989, 0.34530387,\n",
      "       0.27624309, 0.31491713, 0.32596685, 0.10220994, 0.43646409,\n",
      "       0.51104972, 0.25138122, 0.43093923, 0.38674033, 0.49171271,\n",
      "       0.64640884, 0.54972376, 0.5718232 , 0.54972376, 0.6961326 ,\n",
      "       0.63535912, 0.66022099, 0.4640884 , 0.41712707, 0.27071823,\n",
      "       0.56906077, 0.78453039, 0.60220994, 0.70441989, 0.45303867,\n",
      "       0.53867403, 0.74309392, 0.48895028, 0.5801105 , 0.40331492,\n",
      "       0.63535912, 0.47513812, 0.56353591, 0.61049724, 0.65745856,\n",
      "       0.52486188, 0.58839779, 0.6961326 , 0.66298343, 0.70441989,\n",
      "       0.5441989 , 0.78176796, 0.29834254, 0.5801105 , 0.56629834,\n",
      "       0.48066298, 0.39226519, 0.66850829, 0.4281768 , 0.6878453 ,\n",
      "       0.47513812, 0.44198895, 0.62707182, 0.7320442 , 0.53314917,\n",
      "       0.33425414, 0.66022099, 0.46685083, 0.38674033, 0.5718232 ,\n",
      "       0.55524862, 0.62430939, 0.5801105 , 0.68232044, 0.59392265,\n",
      "       0.59668508, 0.43370166, 0.66022099, 0.68508287, 0.44198895,\n",
      "       0.62707182, 0.72651934, 0.30110497, 0.62983425, 0.28729282,\n",
      "       0.28729282, 0.52209945, 0.74585635, 0.39779006, 0.37569061,\n",
      "       0.59392265, 0.7679558 , 0.53038674, 0.65745856, 0.50552486,\n",
      "       0.78176796, 0.19889503, 0.59944751, 0.31767956, 0.65469613,\n",
      "       0.67403315, 0.61325967, 0.79281768, 0.70165746, 0.10220994,\n",
      "       0.44475138, 0.26243094, 0.24585635, 0.64640884, 0.20165746,\n",
      "       0.56353591, 0.46685083, 0.37569061, 0.65469613, 0.69889503,\n",
      "       0.59944751, 0.81767956, 0.19889503, 0.5359116 , 0.54972376,\n",
      "       0.69060773, 0.47513812, 0.71546961, 0.64917127, 0.70718232,\n",
      "       0.10220994, 0.25138122, 0.67679558, 0.71546961, 0.66574586,\n",
      "       0.66574586, 0.63812155, 0.29281768, 0.38121547, 0.83425414,\n",
      "       0.76519337, 0.75966851, 0.77071823, 0.68508287, 0.58839779,\n",
      "       0.10220994, 0.70441989, 0.83149171, 0.85082873, 0.78729282,\n",
      "       0.45856354, 0.26243094, 0.52762431, 0.10220994, 0.36187845,\n",
      "       0.67679558, 0.76243094, 0.67955801, 0.59944751, 0.77624309,\n",
      "       0.48066298, 0.79558011, 0.72375691, 0.46132597, 0.79281768,\n",
      "       0.59392265, 0.28453039, 0.79005525, 0.85082873, 0.7679558 ,\n",
      "       0.65469613, 0.69060773, 0.58839779, 0.66850829, 0.52209945,\n",
      "       0.50552486, 0.68232044, 0.80110497, 0.5359116 , 0.80662983,\n",
      "       0.8038674 , 0.62707182, 0.64364641, 0.77348066, 0.55801105,\n",
      "       0.82596685, 0.7320442 , 0.62430939, 0.48618785, 0.5801105 ,\n",
      "       0.14640884, 0.70165746, 0.50552486]), 'split2_test_score': array([0.10306407, 0.35376045, 0.10306407, 0.48746518, 0.33983287,\n",
      "       0.35097493, 0.64623955, 0.84401114, 0.51253482, 0.28690808,\n",
      "       0.67688022, 0.39275766, 0.24512535, 0.36768802, 0.55431755,\n",
      "       0.13091922, 0.44289694, 0.5097493 , 0.44289694, 0.18662953,\n",
      "       0.42618384, 0.33704735, 0.34818942, 0.60167131, 0.10027855,\n",
      "       0.43454039, 0.18662953, 0.10027855, 0.46796657, 0.10027855,\n",
      "       0.10306407, 0.28412256, 0.19220056, 0.29526462, 0.40668524,\n",
      "       0.42061281, 0.37325905, 0.10027855, 0.19777159, 0.74373259,\n",
      "       0.16713092, 0.33147632, 0.6908078 , 0.26183844, 0.49860724,\n",
      "       0.36211699, 0.3454039 , 0.10027855, 0.29247911, 0.32869081,\n",
      "       0.4902507 , 0.10027855, 0.41504178, 0.10027855, 0.10027855,\n",
      "       0.10027855, 0.10027855, 0.10027855, 0.35933148, 0.35376045,\n",
      "       0.10306407, 0.35376045, 0.74373259, 0.42339833, 0.40389972,\n",
      "       0.17827298, 0.55153203, 0.32311978, 0.40111421, 0.10027855,\n",
      "       0.62674095, 0.46518106, 0.10027855, 0.26740947, 0.51532033,\n",
      "       0.72980501, 0.10306407, 0.6545961 , 0.48467967, 0.32311978,\n",
      "       0.52367688, 0.39832869, 0.67966574, 0.10027855, 0.4735376 ,\n",
      "       0.44289694, 0.30640669, 0.49860724, 0.34818942, 0.40668524,\n",
      "       0.59610028, 0.47075209, 0.60167131, 0.63231198, 0.55431755,\n",
      "       0.45682451, 0.60167131, 0.42896936, 0.46796657, 0.32869081,\n",
      "       0.66016713, 0.78551532, 0.67130919, 0.61281337, 0.4735376 ,\n",
      "       0.64066852, 0.71030641, 0.62674095, 0.66852368, 0.52089136,\n",
      "       0.75208914, 0.545961  , 0.62395543, 0.18662953, 0.62116992,\n",
      "       0.63231198, 0.61002786, 0.67409471, 0.49860724, 0.80222841,\n",
      "       0.45682451, 0.86908078, 0.30083565, 0.51253482, 0.63231198,\n",
      "       0.61559889, 0.40389972, 0.6908078 , 0.55153203, 0.48467967,\n",
      "       0.67409471, 0.73816156, 0.70473538, 0.75766017, 0.36211699,\n",
      "       0.22841226, 0.81337047, 0.32311978, 0.63231198, 0.72980501,\n",
      "       0.40947075, 0.75487465, 0.34818942, 0.62952646, 0.64902507,\n",
      "       0.67409471, 0.53760446, 0.70752089, 0.60167131, 0.28969359,\n",
      "       0.59052925, 0.86072423, 0.32590529, 0.67130919, 0.35376045,\n",
      "       0.48746518, 0.83844011, 0.82451253, 0.74094708, 0.39832869,\n",
      "       0.5264624 , 0.78830084, 0.77437326, 0.56545961, 0.6908078 ,\n",
      "       0.88300836, 0.46239554, 0.48189415, 0.35933148, 0.59331476,\n",
      "       0.7632312 , 0.51810585, 0.89415042, 0.62674095, 0.10027855,\n",
      "       0.56545961, 0.28969359, 0.44568245, 0.25348189, 0.35376045,\n",
      "       0.60445682, 0.68245125, 0.51532033, 0.80222841, 0.76601671,\n",
      "       0.33147632, 0.84401114, 0.28969359, 0.43732591, 0.6183844 ,\n",
      "       0.80222841, 0.55710306, 0.43454039, 0.72423398, 0.81337047,\n",
      "       0.10027855, 0.26462396, 0.88022284, 0.84401114, 0.69359331,\n",
      "       0.81337047, 0.62395543, 0.77715877, 0.38440111, 0.8718663 ,\n",
      "       0.89972145, 0.86629526, 0.91086351, 0.87743733, 0.81337047,\n",
      "       0.5097493 , 0.47910864, 0.8718663 , 0.91922006, 0.85236769,\n",
      "       0.48189415, 0.32590529, 0.50417827, 0.10306407, 0.37604457,\n",
      "       0.42896936, 0.88857939, 0.86350975, 0.85236769, 0.83008357,\n",
      "       0.66573816, 0.8551532 , 0.77715877, 0.4902507 , 0.91086351,\n",
      "       0.66295265, 0.55431755, 0.7994429 , 0.8913649 , 0.57103064,\n",
      "       0.67130919, 0.59331476, 0.60167131, 0.75208914, 0.56267409,\n",
      "       0.73537604, 0.58495822, 0.65738162, 0.58774373, 0.86350975,\n",
      "       0.80501393, 0.6545961 , 0.82729805, 0.86072423, 0.82172702,\n",
      "       0.8913649 , 0.88579387, 0.57660167, 0.62116992, 0.72980501,\n",
      "       0.61002786, 0.74651811, 0.66016713]), 'split3_test_score': array([0.36694678, 0.4929972 , 0.10084034, 0.57142857, 0.48459384,\n",
      "       0.60784314, 0.49859944, 0.79831933, 0.52941176, 0.10084034,\n",
      "       0.21568627, 0.3557423 , 0.18487395, 0.43137255, 0.30532213,\n",
      "       0.10084034, 0.62184874, 0.42016807, 0.42857143, 0.10084034,\n",
      "       0.63585434, 0.32773109, 0.33613445, 0.32492997, 0.10084034,\n",
      "       0.3977591 , 0.23809524, 0.10084034, 0.31932773, 0.10084034,\n",
      "       0.10084034, 0.2605042 , 0.28571429, 0.46218487, 0.30532213,\n",
      "       0.33333333, 0.37254902, 0.10084034, 0.19607843, 0.66386555,\n",
      "       0.24369748, 0.32492997, 0.47338936, 0.22969188, 0.5210084 ,\n",
      "       0.10084034, 0.34453782, 0.19607843, 0.47338936, 0.4929972 ,\n",
      "       0.70028011, 0.10084034, 0.62745098, 0.10084034, 0.43417367,\n",
      "       0.10084034, 0.10084034, 0.10084034, 0.42296919, 0.31932773,\n",
      "       0.10084034, 0.35014006, 0.71148459, 0.51540616, 0.54901961,\n",
      "       0.42016807, 0.35294118, 0.24369748, 0.41736695, 0.10084034,\n",
      "       0.61344538, 0.69747899, 0.32492997, 0.51260504, 0.55182073,\n",
      "       0.70028011, 0.10084034, 0.47619048, 0.10084034, 0.28571429,\n",
      "       0.28011204, 0.40336134, 0.68627451, 0.62745098, 0.42296919,\n",
      "       0.40336134, 0.31932773, 0.51260504, 0.40616246, 0.56582633,\n",
      "       0.65826331, 0.51540616, 0.62464986, 0.6162465 , 0.61904762,\n",
      "       0.6442577 , 0.62184874, 0.49579832, 0.49859944, 0.2464986 ,\n",
      "       0.62184874, 0.70588235, 0.57422969, 0.56582633, 0.35014006,\n",
      "       0.53221289, 0.59103641, 0.75070028, 0.66386555, 0.59103641,\n",
      "       0.85994398, 0.54901961, 0.59103641, 0.59383754, 0.64145658,\n",
      "       0.66386555, 0.70028011, 0.67787115, 0.77030812, 0.71428571,\n",
      "       0.47058824, 0.78991597, 0.34173669, 0.34453782, 0.67787115,\n",
      "       0.44817927, 0.66386555, 0.81792717, 0.59103641, 0.53221289,\n",
      "       0.57422969, 0.44817927, 0.70308123, 0.85154062, 0.35014006,\n",
      "       0.31372549, 0.78431373, 0.52941176, 0.52380952, 0.43137255,\n",
      "       0.29131653, 0.57422969, 0.3557423 , 0.52941176, 0.34453782,\n",
      "       0.4789916 , 0.70588235, 0.74229692, 0.83193277, 0.49019608,\n",
      "       0.58543417, 0.82633053, 0.25490196, 0.40336134, 0.43977591,\n",
      "       0.61344538, 0.77591036, 0.82913165, 0.75910364, 0.28291317,\n",
      "       0.77030812, 0.79551821, 0.20728291, 0.55742297, 0.58543417,\n",
      "       0.8907563 , 0.54061625, 0.64985994, 0.51820728, 0.767507  ,\n",
      "       0.78711485, 0.71708683, 0.77871148, 0.56302521, 0.10084034,\n",
      "       0.58263305, 0.44257703, 0.46218487, 0.51540616, 0.27170868,\n",
      "       0.68347339, 0.64145658, 0.45098039, 0.74509804, 0.28851541,\n",
      "       0.44537815, 0.7394958 , 0.29691877, 0.38655462, 0.66946779,\n",
      "       0.75630252, 0.67226891, 0.67507003, 0.50980392, 0.79831933,\n",
      "       0.10084034, 0.43417367, 0.85994398, 0.88515406, 0.75070028,\n",
      "       0.59943978, 0.23809524, 0.2464986 , 0.35294118, 0.88235294,\n",
      "       0.88235294, 0.88515406, 0.87114846, 0.53781513, 0.79831933,\n",
      "       0.32492997, 0.67787115, 0.86554622, 0.89915966, 0.47058824,\n",
      "       0.48179272, 0.38655462, 0.3837535 , 0.10084034, 0.82913165,\n",
      "       0.43977591, 0.85434174, 0.6162465 , 0.73669468, 0.77030812,\n",
      "       0.54621849, 0.91036415, 0.77310924, 0.4789916 , 0.88235294,\n",
      "       0.6442577 , 0.2464986 , 0.67226891, 0.91316527, 0.71428571,\n",
      "       0.66946779, 0.68067227, 0.66386555, 0.72268908, 0.42857143,\n",
      "       0.4929972 , 0.91316527, 0.87955182, 0.73389356, 0.8487395 ,\n",
      "       0.80392157, 0.8627451 , 0.78991597, 0.8907563 , 0.82633053,\n",
      "       0.88515406, 0.82633053, 0.4929972 , 0.37254902, 0.63865546,\n",
      "       0.69467787, 0.767507  , 0.67787115]), 'split4_test_score': array([0.24507042, 0.32676056, 0.10140845, 0.57183099, 0.6084507 ,\n",
      "       0.3943662 , 0.47042254, 0.72957746, 0.38309859, 0.38309859,\n",
      "       0.36619718, 0.58591549, 0.31549296, 0.45915493, 0.32394366,\n",
      "       0.09859155, 0.56056338, 0.44225352, 0.38028169, 0.10140845,\n",
      "       0.49577465, 0.35211268, 0.31267606, 0.58309859, 0.10140845,\n",
      "       0.4       , 0.1943662 , 0.25915493, 0.37464789, 0.10140845,\n",
      "       0.10140845, 0.25633803, 0.21690141, 0.30985915, 0.55211268,\n",
      "       0.34647887, 0.29859155, 0.10140845, 0.1915493 , 0.61971831,\n",
      "       0.18873239, 0.28450704, 0.53802817, 0.16338028, 0.45352113,\n",
      "       0.34929577, 0.44225352, 0.34084507, 0.22816901, 0.10140845,\n",
      "       0.57464789, 0.10140845, 0.10140845, 0.10140845, 0.34929577,\n",
      "       0.10140845, 0.10140845, 0.10140845, 0.38309859, 0.14647887,\n",
      "       0.10140845, 0.10140845, 0.4       , 0.44507042, 0.31267606,\n",
      "       0.28732394, 0.38873239, 0.32394366, 0.4056338 , 0.10140845,\n",
      "       0.56901408, 0.66197183, 0.54366197, 0.45915493, 0.44788732,\n",
      "       0.70140845, 0.10140845, 0.6084507 , 0.10140845, 0.22535211,\n",
      "       0.27323944, 0.47323944, 0.5915493 , 0.10140845, 0.53521127,\n",
      "       0.4028169 , 0.10140845, 0.31267606, 0.65915493, 0.44507042,\n",
      "       0.5971831 , 0.27323944, 0.52394366, 0.56056338, 0.52676056,\n",
      "       0.51267606, 0.58309859, 0.44225352, 0.45352113, 0.41971831,\n",
      "       0.67042254, 0.67042254, 0.5915493 , 0.64225352, 0.50985915,\n",
      "       0.66478873, 0.69295775, 0.70140845, 0.57746479, 0.47605634,\n",
      "       0.76338028, 0.52676056, 0.6028169 , 0.44788732, 0.50704225,\n",
      "       0.58028169, 0.61971831, 0.58873239, 0.74929577, 0.74084507,\n",
      "       0.45633803, 0.8       , 0.33239437, 0.3915493 , 0.55774648,\n",
      "       0.71549296, 0.58028169, 0.61126761, 0.46197183, 0.65915493,\n",
      "       0.48732394, 0.58028169, 0.46760563, 0.64225352, 0.5971831 ,\n",
      "       0.30985915, 0.70985915, 0.10140845, 0.56619718, 0.4       ,\n",
      "       0.49577465, 0.56619718, 0.30422535, 0.74366197, 0.63098592,\n",
      "       0.45352113, 0.52676056, 0.54366197, 0.71549296, 0.3915493 ,\n",
      "       0.71830986, 0.68169014, 0.24788732, 0.44225352, 0.42253521,\n",
      "       0.38309859, 0.64788732, 0.76056338, 0.57746479, 0.28450704,\n",
      "       0.50704225, 0.77746479, 0.4084507 , 0.81126761, 0.6084507 ,\n",
      "       0.7915493 , 0.70704225, 0.50422535, 0.34366197, 0.78873239,\n",
      "       0.72676056, 0.71549296, 0.8084507 , 0.50140845, 0.10140845,\n",
      "       0.43098592, 0.30140845, 0.74084507, 0.24507042, 0.36619718,\n",
      "       0.57746479, 0.55492958, 0.52394366, 0.76901408, 0.67605634,\n",
      "       0.41408451, 0.67323944, 0.48169014, 0.58028169, 0.54647887,\n",
      "       0.78309859, 0.61690141, 0.50985915, 0.69859155, 0.69859155,\n",
      "       0.10140845, 0.43380282, 0.84507042, 0.53802817, 0.75211268,\n",
      "       0.74929577, 0.49859155, 0.76619718, 0.45352113, 0.85070423,\n",
      "       0.85915493, 0.83661972, 0.82535211, 0.7971831 , 0.75774648,\n",
      "       0.18591549, 0.73802817, 0.75774648, 0.86478873, 0.6       ,\n",
      "       0.46197183, 0.10140845, 0.23098592, 0.34647887, 0.73521127,\n",
      "       0.6       , 0.82535211, 0.8084507 , 0.63943662, 0.76901408,\n",
      "       0.66197183, 0.73521127, 0.74366197, 0.35774648, 0.81408451,\n",
      "       0.64507042, 0.53239437, 0.78873239, 0.88450704, 0.5971831 ,\n",
      "       0.65633803, 0.71549296, 0.74929577, 0.66760563, 0.70985915,\n",
      "       0.49295775, 0.53521127, 0.71267606, 0.67887324, 0.83380282,\n",
      "       0.76619718, 0.7915493 , 0.77464789, 0.78873239, 0.65070423,\n",
      "       0.83943662, 0.76901408, 0.16056338, 0.54084507, 0.69859155,\n",
      "       0.58309859, 0.63380282, 0.52394366]), 'mean_test_score': array([0.27030057, 0.39169472, 0.10183423, 0.55099468, 0.52837926,\n",
      "       0.49423591, 0.50981085, 0.76693517, 0.46792143, 0.32269287,\n",
      "       0.48919734, 0.45300719, 0.23286993, 0.40806348, 0.36395242,\n",
      "       0.18005237, 0.48303947, 0.42094623, 0.40142766, 0.11854732,\n",
      "       0.51091294, 0.35211236, 0.30019532, 0.41433145, 0.11785171,\n",
      "       0.44591956, 0.20371012, 0.17260543, 0.38493837, 0.12984856,\n",
      "       0.10183423, 0.28409254, 0.19621843, 0.32034959, 0.4550977 ,\n",
      "       0.42231013, 0.34822483, 0.10127713, 0.19752124, 0.67490048,\n",
      "       0.24111913, 0.29837027, 0.56575622, 0.29827312, 0.48137072,\n",
      "       0.2708047 , 0.35369908, 0.21766262, 0.40870368, 0.24249981,\n",
      "       0.53980339, 0.10127713, 0.31574218, 0.10127713, 0.30213664,\n",
      "       0.10127713, 0.33091406, 0.10127713, 0.3736208 , 0.25852819,\n",
      "       0.20403203, 0.24963565, 0.52927609, 0.46904928, 0.38366671,\n",
      "       0.36237855, 0.4233579 , 0.29934398, 0.41502213, 0.10402438,\n",
      "       0.62635347, 0.62109176, 0.23454576, 0.44608233, 0.53826158,\n",
      "       0.69516521, 0.16979003, 0.52678013, 0.29859934, 0.32326065,\n",
      "       0.31900594, 0.37895833, 0.5253726 , 0.20659926, 0.47473533,\n",
      "       0.43499201, 0.24460592, 0.46030617, 0.44466481, 0.47911169,\n",
      "       0.64025045, 0.5217144 , 0.57980222, 0.60583506, 0.58584507,\n",
      "       0.56301029, 0.62413716, 0.50633181, 0.43502526, 0.32345486,\n",
      "       0.62792621, 0.74531408, 0.62467281, 0.64956812, 0.42709532,\n",
      "       0.57087323, 0.6452811 , 0.67180175, 0.64414675, 0.49661146,\n",
      "       0.77523143, 0.52487036, 0.54824695, 0.48755054, 0.61454634,\n",
      "       0.60224224, 0.60368481, 0.67681672, 0.69503012, 0.74785032,\n",
      "       0.45701851, 0.82068041, 0.32609042, 0.43992231, 0.61376867,\n",
      "       0.5789099 , 0.49212836, 0.70165822, 0.53731265, 0.61728405,\n",
      "       0.57347597, 0.54666735, 0.62907024, 0.73021618, 0.44544094,\n",
      "       0.33230515, 0.73366276, 0.32756476, 0.51906455, 0.5205562 ,\n",
      "       0.44651596, 0.62590021, 0.38633483, 0.66478633, 0.59149649,\n",
      "       0.55494422, 0.5352953 , 0.67085005, 0.71298983, 0.40620207,\n",
      "       0.66580748, 0.76575615, 0.30563024, 0.56396705, 0.3748487 ,\n",
      "       0.46964501, 0.68214217, 0.80014465, 0.6285776 , 0.33696922,\n",
      "       0.62570093, 0.78518859, 0.48904378, 0.65513494, 0.62694461,\n",
      "       0.84853726, 0.4197019 , 0.58499748, 0.39294089, 0.64271819,\n",
      "       0.72759059, 0.65289895, 0.82955133, 0.59010487, 0.10127713,\n",
      "       0.55201874, 0.33065057, 0.44374891, 0.40405149, 0.29855486,\n",
      "       0.61380816, 0.58726952, 0.4720881 , 0.75299854, 0.62875384,\n",
      "       0.51631906, 0.76103903, 0.29025269, 0.50065213, 0.60263514,\n",
      "       0.76633756, 0.55494164, 0.5807241 , 0.64767883, 0.68426196,\n",
      "       0.10127713, 0.34767545, 0.82108788, 0.7465326 , 0.71418867,\n",
      "       0.70897697, 0.57118132, 0.56049049, 0.3918883 , 0.84937398,\n",
      "       0.84776805, 0.84482224, 0.85144064, 0.7470861 , 0.74211626,\n",
      "       0.2773082 , 0.64351194, 0.83840706, 0.88262361, 0.66292887,\n",
      "       0.4751961 , 0.28504008, 0.44139631, 0.15084831, 0.60276088,\n",
      "       0.50053674, 0.83592105, 0.76333321, 0.69800688, 0.8022067 ,\n",
      "       0.5764128 , 0.82354746, 0.7744165 , 0.44887174, 0.85200175,\n",
      "       0.63891101, 0.3966251 , 0.77823176, 0.88599517, 0.70206907,\n",
      "       0.68201058, 0.6942593 , 0.64262411, 0.70448612, 0.55398148,\n",
      "       0.58987666, 0.64368049, 0.75409894, 0.66442728, 0.8381188 ,\n",
      "       0.80008573, 0.74488477, 0.75270606, 0.83471674, 0.69937654,\n",
      "       0.854868  , 0.81076841, 0.51265257, 0.54590861, 0.69536657,\n",
      "       0.54640307, 0.72264433, 0.62899587]), 'std_test_score': array([0.09247395, 0.05965149, 0.00075595, 0.04553037, 0.1126289 ,\n",
      "       0.11476695, 0.07003669, 0.04683031, 0.05155754, 0.12809092,\n",
      "       0.1718667 , 0.09810882, 0.04775412, 0.04487543, 0.09771013,\n",
      "       0.09468291, 0.12570598, 0.05927508, 0.07104276, 0.03404394,\n",
      "       0.08873144, 0.02336377, 0.04470498, 0.14641172, 0.03361893,\n",
      "       0.04539631, 0.01789139, 0.08879106, 0.06124599, 0.05733203,\n",
      "       0.00075595, 0.04498227, 0.05905712, 0.07280552, 0.0973032 ,\n",
      "       0.07520247, 0.03909339, 0.0006653 , 0.00358014, 0.04077837,\n",
      "       0.05644782, 0.02485032, 0.07316576, 0.15510737, 0.03134546,\n",
      "       0.14162582, 0.04644895, 0.10951865, 0.12486208, 0.14874513,\n",
      "       0.08965071, 0.0006653 , 0.19275124, 0.0006653 , 0.17315937,\n",
      "       0.0006653 , 0.2893829 , 0.0006653 , 0.03759989, 0.11302661,\n",
      "       0.20430404, 0.12077588, 0.17328279, 0.03263118, 0.09047391,\n",
      "       0.12660079, 0.0687258 , 0.03154089, 0.0297604 , 0.00571594,\n",
      "       0.04496264, 0.08288661, 0.17715773, 0.10720494, 0.0527424 ,\n",
      "       0.02167821, 0.13610143, 0.11517247, 0.25143539, 0.06982251,\n",
      "       0.10324085, 0.06235204, 0.15934204, 0.2104268 , 0.04183138,\n",
      "       0.04071682, 0.07740041, 0.0828537 , 0.11010652, 0.05316722,\n",
      "       0.04035159, 0.16870012, 0.03370964, 0.0450932 , 0.06410429,\n",
      "       0.0716282 , 0.02959318, 0.0997065 , 0.05517285, 0.06130637,\n",
      "       0.03589824, 0.04803347, 0.04438187, 0.05787726, 0.06590333,\n",
      "       0.0704901 , 0.09320036, 0.10660649, 0.05836719, 0.06108338,\n",
      "       0.08431381, 0.02650148, 0.09617967, 0.16182607, 0.05501131,\n",
      "       0.04739219, 0.06420622, 0.05118927, 0.10770962, 0.03713842,\n",
      "       0.059599  , 0.03739329, 0.02305015, 0.09069776, 0.045342  ,\n",
      "       0.09984695, 0.10970567, 0.06816742, 0.08277121, 0.09233555,\n",
      "       0.08261442, 0.10857152, 0.08656527, 0.07367028, 0.10044233,\n",
      "       0.0801085 , 0.05652546, 0.15717922, 0.08204215, 0.11956512,\n",
      "       0.09042312, 0.06801111, 0.09851374, 0.07950804, 0.13238123,\n",
      "       0.08033221, 0.09320857, 0.06873317, 0.07435107, 0.06671452,\n",
      "       0.08545752, 0.06683444, 0.05465605, 0.11693944, 0.05406672,\n",
      "       0.12103495, 0.11235543, 0.03895992, 0.13195509, 0.04686173,\n",
      "       0.10666641, 0.01100547, 0.18454254, 0.09253011, 0.08331502,\n",
      "       0.05077753, 0.20036381, 0.08062728, 0.07210444, 0.13707052,\n",
      "       0.04323257, 0.07752305, 0.04581471, 0.06846476, 0.0006653 ,\n",
      "       0.11065202, 0.06389971, 0.1685639 , 0.15558493, 0.05955462,\n",
      "       0.04354449, 0.07423453, 0.05440327, 0.05307236, 0.17267096,\n",
      "       0.16255833, 0.06193813, 0.10612718, 0.07552898, 0.04768496,\n",
      "       0.04123412, 0.08283679, 0.10353169, 0.07422127, 0.14767654,\n",
      "       0.0006653 , 0.07888619, 0.07334889, 0.12097025, 0.03338064,\n",
      "       0.07274041, 0.20261082, 0.23869363, 0.03318413, 0.02668804,\n",
      "       0.04707259, 0.04561069, 0.04874913, 0.1227919 , 0.08027781,\n",
      "       0.13819763, 0.09110021, 0.04274996, 0.02430641, 0.13837237,\n",
      "       0.01276093, 0.10028474, 0.12094905, 0.09781797, 0.19495847,\n",
      "       0.11860497, 0.04193615, 0.09802609, 0.08917242, 0.03888945,\n",
      "       0.07453086, 0.05852522, 0.0445379 , 0.04718005, 0.04333267,\n",
      "       0.02348448, 0.12599949, 0.05625887, 0.02011404, 0.10730324,\n",
      "       0.03869934, 0.06362046, 0.05919321, 0.03256288, 0.09074197,\n",
      "       0.11371934, 0.14777763, 0.07771211, 0.0918057 , 0.01880279,\n",
      "       0.01820578, 0.08944216, 0.06314   , 0.04542012, 0.10672646,\n",
      "       0.02766476, 0.05423171, 0.18940973, 0.11475257, 0.08453877,\n",
      "       0.20508397, 0.05020842, 0.10167282]), 'rank_test_score': array([228, 190, 250, 121, 131, 146, 141,  26, 159, 211, 148, 163, 235,\n",
      "       183, 197, 242, 151, 178, 186, 247, 140, 200, 217, 181, 248, 167,\n",
      "       239, 243, 192, 246, 250, 225, 241, 212, 162, 177, 201, 252, 240,\n",
      "        60, 233, 221, 113, 222, 152, 227, 199, 236, 182, 232, 126, 252,\n",
      "       214, 252, 216, 252, 205, 252, 196, 229, 238, 230, 130, 158, 193,\n",
      "       198, 176, 218, 180, 249,  85,  90, 234, 166, 127,  53, 244, 132,\n",
      "       219, 210, 213, 194, 133, 237, 155, 174, 231, 160, 169, 153,  77,\n",
      "       135, 107,  95, 104, 115,  89, 142, 173, 209,  83,  37,  88,  69,\n",
      "       175, 112,  71,  61,  72, 145,  24, 134, 122, 150,  92,  99,  96,\n",
      "        59,  54,  34, 161,  17, 208, 172,  94, 108, 147,  49, 128,  91,\n",
      "       110, 123,  79,  41, 168, 204,  40, 207, 137, 136, 165,  86, 191,\n",
      "        64, 100, 117, 129,  62,  45, 184,  63,  28, 215, 114, 195, 157,\n",
      "        57,  20,  82, 203,  87,  22, 149,  67,  84,   7, 179, 105, 188,\n",
      "        75,  42,  68,  14, 101, 252, 120, 206, 170, 185, 220,  93, 103,\n",
      "       156,  32,  81, 138,  30, 223, 143,  98,  27, 118, 106,  70,  56,\n",
      "       252, 202,  16,  36,  44,  46, 111, 116, 189,   6,   8,   9,   5,\n",
      "        35,  39, 226,  74,  10,   2,  66, 154, 224, 171, 245,  97, 144,\n",
      "        12,  29,  51,  19, 109,  15,  25, 164,   4,  78, 187,  23,   1,\n",
      "        48,  58,  55,  76,  47, 119, 102,  73,  31,  65,  11,  21,  38,\n",
      "        33,  13,  50,   3,  18, 139, 125,  52, 124,  43,  80])}\n"
     ]
    }
   ],
   "source": [
    "print (gs.cv_results_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>(9, 6, 6)</td>\n",
       "      <td>0.885995</td>\n",
       "      <td>0.314639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>(8, 9, 8)</td>\n",
       "      <td>0.882624</td>\n",
       "      <td>0.318159</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>(9, 8, 9)</td>\n",
       "      <td>0.854868</td>\n",
       "      <td>0.353578</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>(9, 5, 9)</td>\n",
       "      <td>0.852002</td>\n",
       "      <td>0.341285</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>(8, 8, 9)</td>\n",
       "      <td>0.851441</td>\n",
       "      <td>0.336406</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>(8, 8, 6)</td>\n",
       "      <td>0.849374</td>\n",
       "      <td>0.373785</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>(7, 9)</td>\n",
       "      <td>0.848537</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>(8, 8, 7)</td>\n",
       "      <td>0.847768</td>\n",
       "      <td>0.347465</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>(8, 8, 8)</td>\n",
       "      <td>0.844822</td>\n",
       "      <td>0.326771</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>(8, 9, 7)</td>\n",
       "      <td>0.838407</td>\n",
       "      <td>0.337714</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>(9, 8)</td>\n",
       "      <td>0.838119</td>\n",
       "      <td>0.302084</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>(9, 4, 8)</td>\n",
       "      <td>0.835921</td>\n",
       "      <td>0.329141</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>(9, 8, 7)</td>\n",
       "      <td>0.834717</td>\n",
       "      <td>0.360936</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>(8,)</td>\n",
       "      <td>0.829551</td>\n",
       "      <td>0.219437</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>(9, 5, 6)</td>\n",
       "      <td>0.823547</td>\n",
       "      <td>0.337315</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>(8, 7, 6)</td>\n",
       "      <td>0.821088</td>\n",
       "      <td>0.323310</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>(6, 8, 9)</td>\n",
       "      <td>0.820680</td>\n",
       "      <td>0.321989</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>(9, 9)</td>\n",
       "      <td>0.810768</td>\n",
       "      <td>0.298587</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>(9, 5, 4)</td>\n",
       "      <td>0.802207</td>\n",
       "      <td>0.308910</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>(7, 7, 9)</td>\n",
       "      <td>0.800145</td>\n",
       "      <td>0.320946</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_hidden_layer_sizes  mean_test_score  mean_fit_time  rank_test_score\n",
       "233                (9, 6, 6)         0.885995       0.314639                1\n",
       "213                (8, 9, 8)         0.882624       0.318159                2\n",
       "250                (9, 8, 9)         0.854868       0.353578                3\n",
       "229                (9, 5, 9)         0.852002       0.341285                4\n",
       "207                (8, 8, 9)         0.851441       0.336406                5\n",
       "204                (8, 8, 6)         0.849374       0.373785                6\n",
       "165                   (7, 9)         0.848537       0.279600                7\n",
       "205                (8, 8, 7)         0.847768       0.347465                8\n",
       "206                (8, 8, 8)         0.844822       0.326771                9\n",
       "212                (8, 9, 7)         0.838407       0.337714               10\n",
       "244                   (9, 8)         0.838119       0.302084               11\n",
       "221                (9, 4, 8)         0.835921       0.329141               12\n",
       "248                (9, 8, 7)         0.834717       0.360936               13\n",
       "172                     (8,)         0.829551       0.219437               14\n",
       "226                (9, 5, 6)         0.823547       0.337315               15\n",
       "197                (8, 7, 6)         0.821088       0.323310               16\n",
       "121                (6, 8, 9)         0.820680       0.321989               17\n",
       "251                   (9, 9)         0.810768       0.298587               18\n",
       "224                (9, 5, 4)         0.802207       0.308910               19\n",
       "157                (7, 7, 9)         0.800145       0.320946               20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_summary = pd.DataFrame(gs.cv_results_)[['param_hidden_layer_sizes','mean_test_score','mean_fit_time','rank_test_score']]\n",
    "display(data_summary.sort_values('rank_test_score').head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0., 10., ..., 16.,  8.,  0.],\n",
       "       [ 0.,  1., 12., ...,  9.,  4.,  0.],\n",
       "       [ 0.,  4., 16., ..., 16.,  8.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ..., 15.,  4.,  0.],\n",
       "       [ 0.,  0.,  6., ..., 16., 16., 12.],\n",
       "       [ 0.,  3., 14., ...,  0.,  0.,  0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 1.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x_train)\n",
    "display(y_train_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = OneHotEncoder()\n",
    "y_train_hot = one_hot.fit_transform(y_train.reshape(-1,1)).todense()\n",
    "y_test_hot = one_hot.fit_transform(y_test.reshape(-1,1)).todense()\n",
    "hidden_nodes = [9,6,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd started at: Sun Oct 13 21:25:03 2019\n",
      "gd ended at: Sun Oct 13 21:26:21 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['gd', 100, 0.6939555999997538, 0.08888888888888889],\n",
       " ['gd', 500, 3.5576576000021305, 0.08888888888888889],\n",
       " ['gd', 1000, 7.074385899992194, 0.08888888888888889],\n",
       " ['gd', 10000, 66.42403920000652, 0.08888888888888889]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gd_list = []\n",
    "max_iters = [100,500,1000,10000]\n",
    "print(\"gd started at: {}\".format(time.ctime()))\n",
    "for iters in max_iters: \n",
    "    t_start = timer()\n",
    "    nn_model = mlrose.NeuralNetwork(hidden_nodes=hidden_nodes,\n",
    "                                   algorithm='gradient_descent',\n",
    "                                   max_iters = iters,\n",
    "                                    random_state = 3)\n",
    "    nn_model.fit(x_train, y_train_hot)\n",
    "    y_test_pred = nn_model.predict(x_test)\n",
    "    score = metrics.accuracy_score(y_test_hot, y_test_pred)\n",
    "    t_end = timer()\n",
    "    gd_list.append(['gd',iters,t_end-t_start,score])\n",
    "print(\"gd ended at: {}\".format(time.ctime()))\n",
    "display(gd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rhc started at: Sun Oct 13 20:54:12 2019\n",
      "rhc ended at: Sun Oct 13 21:22:11 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['rhc', 500000, 1679.2625025000016, 0.55]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rhc_list = []\n",
    "max_iters = [500000]\n",
    "print(\"rhc started at: {}\".format(time.ctime()))\n",
    "for iters in max_iters: \n",
    "    t_start = timer()\n",
    "    nn_model = mlrose.NeuralNetwork(hidden_nodes=hidden_nodes,\n",
    "                                   algorithm='random_hill_climb',\n",
    "                                   max_iters = iters,\n",
    "                                    random_state = 2)\n",
    "    nn_model.fit(x_train, y_train_hot)\n",
    "    y_test_pred = nn_model.predict(x_test)\n",
    "    score = metrics.accuracy_score(y_test_hot, y_test_pred)\n",
    "    t_end = timer()\n",
    "    rhc_list.append(['rhc',iters,t_end-t_start,score])\n",
    "print(\"rhc ended at: {}\".format(time.ctime()))\n",
    "display(rhc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa started at: Sun Oct 13 12:33:22 2019\n",
      "sa ended at: Sun Oct 13 13:57:46 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['sa', 100, 0.6225819999963278, 0.10277777777777777],\n",
       " ['sa', 500, 3.444372399986605, 0.06111111111111111],\n",
       " ['sa', 1000, 6.512301300012041, 0.125],\n",
       " ['sa', 10000, 55.62880529998802, 0.39444444444444443],\n",
       " ['sa', 50000, 258.1293552999996, 0.5083333333333333],\n",
       " ['sa', 100000, 501.00512020000315, 0.6138888888888889],\n",
       " ['sa', 250000, 1429.0439156000066, 0.7416666666666667],\n",
       " ['sa', 500000, 2810.1020749000018, 0.8111111111111111]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sa_list = []\n",
    "max_iters = [100,500,1000,10000,50000,100000,250000,500000]\n",
    "print(\"sa started at: {}\".format(time.ctime()))\n",
    "for iters in max_iters: \n",
    "    t_start = timer()\n",
    "    nn_model = mlrose.NeuralNetwork(hidden_nodes=hidden_nodes,\n",
    "                                   algorithm='simulated_annealing',\n",
    "                                   max_iters = iters,\n",
    "                                    random_state = 2)\n",
    "    nn_model.fit(x_train, y_train_hot)\n",
    "    y_test_pred = nn_model.predict(x_test)\n",
    "    score = metrics.accuracy_score(y_test_hot, y_test_pred)\n",
    "    t_end = timer()\n",
    "    sa_list.append(['sa',iters,t_end-t_start,score])\n",
    "print(\"sa ended at: {}\".format(time.ctime()))\n",
    "display(sa_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa started at: Sun Oct 13 14:41:31 2019\n",
      "ga ended at: Sun Oct 13 17:12:45 2019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['ga', 100, 90.23694410000462, 0.08888888888888889],\n",
       " ['ga', 1000, 871.9284616999939, 0.16666666666666666],\n",
       " ['ga', 10000, 8111.876126499992, 0.19166666666666668]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ga_list = []\n",
    "max_iters = [100,1000,10000]\n",
    "print(\"sa started at: {}\".format(time.ctime()))\n",
    "for iters in max_iters: \n",
    "    t_start = timer()\n",
    "    nn_model = mlrose.NeuralNetwork(hidden_nodes=hidden_nodes,\n",
    "                                   algorithm='genetic_alg',\n",
    "                                   max_iters = iters,\n",
    "                                    random_state = 2)\n",
    "    nn_model.fit(x_train, y_train_hot)\n",
    "    y_test_pred = nn_model.predict(x_test)\n",
    "    score = metrics.accuracy_score(y_test_hot, y_test_pred)\n",
    "    t_end = timer()\n",
    "    ga_list.append(['ga',iters,t_end-t_start,score])\n",
    "print(\"ga ended at: {}\".format(time.ctime()))\n",
    "display(ga_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
